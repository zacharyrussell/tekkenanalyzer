# -*- coding: utf-8 -*-

'''
Used Google colab for training so I could leverage CUDA
(I dont have an nvidia GPU)
'''




"""InputTrainer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_i807LQjnJtbRUvZRysEuJOmM2S2tToB
"""

# Commented out IPython magic to ensure Python compatibility.
# Step 1: Setup the Colab Environment
!pip install -q torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2
!git clone https://github.com/ultralytics/yolov5  # Clone YOLOv5 repository
# %cd yolov5
!pip install -qr requirements.txt  # Install dependencies

# Step 2: Prepare your dataset
# Upload your dataset to Google Drive and mount the drive (alternatively, you can upload directly to Colab)
from google.colab import drive
drive.mount('/content/drive')

# Assume dataset is in Google Drive under 'My Drive/your_dataset_path'
# Make sure your dataset directory has two subdirectories: 'images' and 'labels'
# and it conforms to the required format (train, val, test splits)

# Step 3: Modify Configuration Files
# Create or modify configuration files to match your dataset structure and training parameters
# This usually includes editing the .yaml file that describes the dataset paths and model parameters

# Example dataset.yaml content:
'''
train: /content/drive/My Drive/input_dataset/train/images
val: /content/drive/My Drive/input_dataset/val/images

nc: 15  # number of classes
names: ['d', 'df', 'f', 'uf', 'u', 'ub', 'b', 'db', '1', '2', '3', '4', '1+2', '3+4', '2+3']
'''

# Step 4: Train the Model

!python train.py --img 640 --batch 16 --epochs 50 --data /content/data.yaml --weights yolov5s.pt --cache